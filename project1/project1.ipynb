{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import deepchem as dc\n",
    "from deepchem.molnet import load_delaney\n",
    "from deepchem.models import GraphConvModel\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Setting up model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading raw samples now.\n",
      "shard_size: 8192\n",
      "About to start loading CSV from /Users/KHatti001/OneDrive - University of Dundee/project1_data/previousDir/Series4_firstSet_trimmed_subset.csv\n",
      "Loading shard 1 of size 8192.\n",
      "Featurizing sample 0\n",
      "TIMING: featurizing shard 0 took 1.427 s\n",
      "TIMING: dataset construction took 1.444 s\n",
      "Loading dataset from disk.\n",
      "About to transform data\n",
      "TIMING: dataset construction took 0.011 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.007 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.008 s\n",
      "Loading dataset from disk.\n",
      "TIMING: dataset construction took 0.006 s\n",
      "Loading dataset from disk.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "deepchem.data.datasets.DiskDataset"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##input malaria file\n",
    "# delaney_tasks = ['Desired_property']\n",
    "delaney_tasks = ['CL mouse GEOM_MEAN']\n",
    "\n",
    "# featurizer = dc.feat.ConvMolFeaturizer()\n",
    "featurizer = dc.feat.RDKitDescriptors()\n",
    "\n",
    "input_dataset = \"/Users/KHatti001/OneDrive - University of Dundee/project1_data/previousDir/Series4_firstSet_trimmed_subset.csv\"\n",
    "\n",
    "loader = dc.data.CSVLoader(tasks=delaney_tasks, smiles_field=\"SMILES\", featurizer=featurizer)\n",
    "dataset = loader.featurize(input_dataset, shard_size=8192)\n",
    "\n",
    "# Options of transformers\n",
    "# dc.trans.LogTransformer\n",
    "# dc.trans.ClippingTransformer\n",
    "# dc.trans.NormalizationTransformer\n",
    "# dc.trans.AtomicNormalizationTransformer\n",
    "# dc.trans.BalancingTransformer\n",
    "# dc.trans.CDFTransformer\n",
    "# dc.trans.PowerTransformer\n",
    "# dc.trans.CoulombRandomizationTransformer\n",
    "# dc.trans.CoulombBinarizationTransformer\n",
    "\n",
    "\n",
    "# Initialize transformers\n",
    "transformers = [\n",
    "  dc.trans.NormalizationTransformer(\n",
    "      transform_y=True, dataset=dataset)\n",
    "]\n",
    "\n",
    "# transformers = [\n",
    "#   dc.trans.BalancingTransformer(dataset=dataset)\n",
    "# ]\n",
    "\n",
    "print(\"About to transform data\")\n",
    "for transformer in transformers:\n",
    "    dataset = transformer.transform(dataset)\n",
    "\n",
    "# splitters = {\n",
    "#   'index': dc.splits.IndexSplitter(),\n",
    "#   'random': dc.splits.RandomSplitter(),\n",
    "#   'scaffold': dc.splits.ScaffoldSplitter()\n",
    "# }\n",
    "splitter = dc.splits.ScaffoldSplitter()\n",
    "train_dataset, valid_dataset, test_dataset = splitter.train_valid_test_split(dataset, \n",
    "                                                                            frac_train = 0.8, \n",
    "                                                                             frac_valid  = 0.1, \n",
    "                                                                             frac_test  = 0.1\n",
    "                                                                            )\n",
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method GraphConv.call of <deepchem.models.layers.GraphConv object at 0x7f8ac6f9eb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GraphConv.call of <deepchem.models.layers.GraphConv object at 0x7f8ac6f9eb38>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method GraphConv.call of <deepchem.models.layers.GraphConv object at 0x7f8ac6f9eb38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GraphConv.call of <deepchem.models.layers.GraphConv object at 0x7f8ac6f9eb38>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method GraphPool.call of <deepchem.models.layers.GraphPool object at 0x7f8ad102c2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GraphPool.call of <deepchem.models.layers.GraphPool object at 0x7f8ad102c2e8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method GraphPool.call of <deepchem.models.layers.GraphPool object at 0x7f8ad102c2e8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GraphPool.call of <deepchem.models.layers.GraphPool object at 0x7f8ad102c2e8>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method GraphConv.call of <deepchem.models.layers.GraphConv object at 0x7f8ad1026f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GraphConv.call of <deepchem.models.layers.GraphConv object at 0x7f8ad1026f98>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method GraphConv.call of <deepchem.models.layers.GraphConv object at 0x7f8ad1026f98>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GraphConv.call of <deepchem.models.layers.GraphConv object at 0x7f8ad1026f98>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method GraphPool.call of <deepchem.models.layers.GraphPool object at 0x7f8ad309b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GraphPool.call of <deepchem.models.layers.GraphPool object at 0x7f8ad309b550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method GraphPool.call of <deepchem.models.layers.GraphPool object at 0x7f8ad309b550>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GraphPool.call of <deepchem.models.layers.GraphPool object at 0x7f8ad309b550>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method GraphGather.call of <deepchem.models.layers.GraphGather object at 0x7f8ad3417588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GraphGather.call of <deepchem.models.layers.GraphGather object at 0x7f8ad3417588>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method GraphGather.call of <deepchem.models.layers.GraphGather object at 0x7f8ad3417588>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method GraphGather.call of <deepchem.models.layers.GraphGather object at 0x7f8ad3417588>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method TrimGraphOutput.call of <deepchem.models.graph_models.TrimGraphOutput object at 0x7f8ad3951240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TrimGraphOutput.call of <deepchem.models.graph_models.TrimGraphOutput object at 0x7f8ad3951240>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method TrimGraphOutput.call of <deepchem.models.graph_models.TrimGraphOutput object at 0x7f8ad3951240>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TrimGraphOutput.call of <deepchem.models.graph_models.TrimGraphOutput object at 0x7f8ad3951240>>: AttributeError: module 'gast' has no attribute 'Index'\n"
     ]
    }
   ],
   "source": [
    "# Load Delaney dataset\n",
    "# delaney_tasks, delaney_datasets, transformers = load_delaney(\n",
    "#     featurizer='GraphConv', split='index')\n",
    "# train_dataset, valid_dataset, test_dataset = dataset\n",
    "\n",
    "# Fit models\n",
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score, np.mean)\n",
    "\n",
    "# Do setup required for tf/keras models\n",
    "# Number of features on conv-mols\n",
    "n_feat = 80\n",
    "# Batch size of models\n",
    "batch_size = 128\n",
    "model = GraphConvModel(\n",
    "    len(delaney_tasks), \n",
    "#     graph_conv_layers=[128,128],\n",
    "#     dense_layer_size=256,\n",
    "    batch_size=batch_size, mode='regression')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data length 167\n",
      "validation data length 21\n"
     ]
    }
   ],
   "source": [
    "print(\"training data length\", len(train_dataset))\n",
    "print(\"validation data length\", len(valid_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'atom_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-410-9a6b81aed854>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnb_epoch_value\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnb_epoch_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalid_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_and_store_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epoch_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mepoch_inputs_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_epoch_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mvalid_scores_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_scores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-410-9a6b81aed854>\u001b[0m in \u001b[0;36mrun_and_store_results\u001b[0;34m(nb_epoch_value)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mscoring_function_used\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mean-pearson_r2_score\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#     scoring_function_used = \"r2_score\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#     print(\"Evaluating model\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/KHatti001/opt/anaconda3/envs/chem_ml/lib/python3.6/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, nb_epoch, max_checkpoints_to_keep, checkpoint_interval, deterministic, restore, variables, loss, callbacks)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             deterministic=deterministic), max_checkpoints_to_keep,\n\u001b[0;32m--> 307\u001b[0;31m         checkpoint_interval, restore, variables, loss, callbacks)\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   def fit_generator(self,\n",
      "\u001b[0;32m/Users/KHatti001/opt/anaconda3/envs/chem_ml/lib/python3.6/site-packages/deepchem/models/keras_model.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, max_checkpoints_to_keep, checkpoint_interval, restore, variables, loss, callbacks)\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;31m# Main training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 360\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    361\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_training_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrestore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/KHatti001/opt/anaconda3/envs/chem_ml/lib/python3.6/site-packages/deepchem/models/graph_models.py\u001b[0m in \u001b[0;36mdefault_generator\u001b[0;34m(self, dataset, epochs, mode, deterministic, pad_batches)\u001b[0m\n\u001b[1;32m    637\u001b[0m           y_b = to_one_hot(y_b.flatten(), self.n_classes).reshape(\n\u001b[1;32m    638\u001b[0m               -1, self.n_tasks, self.n_classes)\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0mmultiConvMol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvMol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magglomerate_mols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_b\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'predict'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/KHatti001/opt/anaconda3/envs/chem_ml/lib/python3.6/site-packages/deepchem/feat/mol_graphs.py\u001b[0m in \u001b[0;36magglomerate_mols\u001b[0;34m(mols, max_deg, min_deg)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;31m# Results should be sorted by (atom_degree, mol_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0matoms_by_deg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_features\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0mdegree_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_list\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Mergesort is a \"stable\" sort, so the array maintains it's secondary sort of mol_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/KHatti001/opt/anaconda3/envs/chem_ml/lib/python3.6/site-packages/deepchem/feat/mol_graphs.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;31m# Results should be sorted by (atom_degree, mol_index)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m     \u001b[0matoms_by_deg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matom_features\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0mdegree_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree_list\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Mergesort is a \"stable\" sort, so the array maintains it's secondary sort of mol_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'atom_features'"
     ]
    }
   ],
   "source": [
    "# Fit trained model\n",
    "def run_and_store_results(nb_epoch_value):\n",
    "    scoring_function_used = \"mean-pearson_r2_score\"\n",
    "#     scoring_function_used = \"r2_score\"\n",
    "    model.fit(train_dataset, nb_epoch=nb_epoch_value)\n",
    "\n",
    "#     print(\"Evaluating model\")\n",
    "    train_scores =  model.evaluate(train_dataset, [metric], transformers)\n",
    "    valid_scores = model.evaluate(valid_dataset, [metric], transformers)\n",
    "    print(\"printing some value\", train_scores[scoring_function_used])\n",
    "    return train_scores[scoring_function_used],valid_scores[scoring_function_used]\n",
    "\n",
    "#     print(\"Train scores\")\n",
    "#     print(train_scores)\n",
    "\n",
    "#     print(\"Validation scores\")\n",
    "#     print(valid_scores)\n",
    "\n",
    "# model.restore()\n",
    "\n",
    "valid_scores_list=[]\n",
    "train_scores_list=[]\n",
    "epoch_inputs_list=[]\n",
    "# for nb_epoch_value in range(0,50,15):\n",
    "for nb_epoch_value in [100,300]:\n",
    "    print (nb_epoch_value)\n",
    "    train_scores,valid_scores = run_and_store_results(nb_epoch_value)\n",
    "    epoch_inputs_list.append(nb_epoch_value)\n",
    "    valid_scores_list.append(valid_scores)\n",
    "    train_scores_list.append(train_scores)\n",
    "    \n",
    "print(epoch_inputs_list)\n",
    "print(valid_scores_list)\n",
    "print(train_scores_list)\n",
    "\n",
    "    \n",
    "# dir(train_scores)\n",
    "# print(dic[\"C\"])\n",
    "# print(valid_scores[\"mean-pearson_r2_score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_inputs_list, valid_scores_list, label=\"validation\")\n",
    "plt.plot(epoch_inputs_list, train_scores_list, label=\"training\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save()\n",
    "model = model.load_from_dir('models')\n",
    "valid_scores = model.evaluate(valid_dataset, [metric], transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "jinga=[]\n",
    "jinga.append(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jinga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
